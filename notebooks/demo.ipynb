{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "771aea11",
   "metadata": {},
   "source": [
    "{\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Whisper Technical Terms Fine-tuning Demo\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook demonstrates how to fine-tune Whisper models for better recognition of technical terms like Maven, GitHub, Git, Portkey, OpenAI, ChatGPT, LLM, Groq, and Grok.\\n\",\n",
    "    \"\\n\",\n",
    "    \"## Setup\\n\",\n",
    "    \"\\n\",\n",
    "    \"Make sure you've installed all dependencies and have a GPU available for training.\"\n",
    "   ]\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4915bbfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'cell_type': 'code',\n",
       "  'execution_count': None,\n",
       "  'metadata': {},\n",
       "  'outputs': [],\n",
       "  'source': ['import sys\\n',\n",
       "   'import os\\n',\n",
       "   'from pathlib import Path\\n',\n",
       "   'import torch\\n',\n",
       "   'import yaml\\n',\n",
       "   'import json\\n',\n",
       "   'import asyncio\\n',\n",
       "   '\\n',\n",
       "   '# Add project root to path\\n',\n",
       "   \"project_root = Path().cwd().parent if Path().cwd().name == 'notebooks' else Path().cwd()\\n\",\n",
       "   'sys.path.append(str(project_root))\\n',\n",
       "   '\\n',\n",
       "   'print(f\"Project root: {project_root}\")\\n',\n",
       "   'print(f\"CUDA available: {torch.cuda.is_available()}\")\\n',\n",
       "   'if torch.cuda.is_available():\\n',\n",
       "   '    print(f\"GPU: {torch.cuda.get_device_name()}\")\\n',\n",
       "   '    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")']},)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import sys\\n\",\n",
    "    \"import os\\n\",\n",
    "    \"from pathlib import Path\\n\",\n",
    "    \"import torch\\n\",\n",
    "    \"import yaml\\n\",\n",
    "    \"import json\\n\",\n",
    "    \"import asyncio\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Add project root to path\\n\",\n",
    "    \"project_root = Path().cwd().parent if Path().cwd().name == 'notebooks' else Path().cwd()\\n\",\n",
    "    \"sys.path.append(str(project_root))\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Project root: {project_root}\\\")\\n\",\n",
    "    \"print(f\\\"CUDA available: {torch.cuda.is_available()}\\\")\\n\",\n",
    "    \"if torch.cuda.is_available():\\n\",\n",
    "    \"    print(f\\\"GPU: {torch.cuda.get_device_name()}\\\")\\n\",\n",
    "    \"    print(f\\\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\\\")\"\n",
    "   ]\n",
    "  },"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea518b5c",
   "metadata": {},
   "source": [
    "{\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Load Configuration\\n\",\n",
    "    \"\\n\",\n",
    "    \"Load the project configuration and examine the technical terms we'll be working with.\"\n",
    "   ]\n",
    "  },"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "901eccaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'cell_type': 'code',\n",
       "  'execution_count': None,\n",
       "  'metadata': {},\n",
       "  'outputs': [],\n",
       "  'source': ['# Load configuration\\n',\n",
       "   'config_path = project_root / \"config\" / \"config.yaml\"\\n',\n",
       "   \"with open(config_path, 'r') as f:\\n\",\n",
       "   '    config = yaml.safe_load(f)\\n',\n",
       "   '\\n',\n",
       "   'print(\"Configuration loaded:\")\\n',\n",
       "   'print(f\"Model: {config[\\'model\\'][\\'name\\']}\")\\n',\n",
       "   'print(f\"Training epochs: {config[\\'training\\'][\\'num_epochs\\']}\")\\n',\n",
       "   'print(f\"Batch size: {config[\\'training\\'][\\'batch_size\\']}\")\\n',\n",
       "   'print(f\"Learning rate: {config[\\'training\\'][\\'learning_rate\\']}\")']},)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Load configuration\\n\",\n",
    "    \"config_path = project_root / \\\"config\\\" / \\\"config.yaml\\\"\\n\",\n",
    "    \"with open(config_path, 'r') as f:\\n\",\n",
    "    \"    config = yaml.safe_load(f)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Configuration loaded:\\\")\\n\",\n",
    "    \"print(f\\\"Model: {config['model']['name']}\\\")\\n\",\n",
    "    \"print(f\\\"Training epochs: {config['training']['num_epochs']}\\\")\\n\",\n",
    "    \"print(f\\\"Batch size: {config['training']['batch_size']}\\\")\\n\",\n",
    "    \"print(f\\\"Learning rate: {config['training']['learning_rate']}\\\")\"\n",
    "   ]\n",
    "  },"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1185ec86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'cell_type': 'code',\n",
       "  'execution_count': None,\n",
       "  'metadata': {},\n",
       "  'outputs': [],\n",
       "  'source': ['# Load and display technical terms\\n',\n",
       "   'terms_file = project_root / \"data\" / \"tech_terms.json\"\\n',\n",
       "   'if terms_file.exists():\\n',\n",
       "   \"    with open(terms_file, 'r') as f:\\n\",\n",
       "   '        tech_terms = json.load(f)\\n',\n",
       "   '    \\n',\n",
       "   '    print(\"Technical Terms by Category:\")\\n',\n",
       "   \"    for category, terms in tech_terms['technical_terms'].items():\\n\",\n",
       "   '        if isinstance(terms, list):\\n',\n",
       "   '            print(f\"\\\\n{category.upper()}:\")\\n',\n",
       "   '            for term_data in terms:\\n',\n",
       "   \"                term = term_data['term']\\n\",\n",
       "   \"                variations = term_data.get('variations', [])\\n\",\n",
       "   '                print(f\"  - {term} ({\\', \\'.join(variations) if variations else \\'no variations\\'})\")\\nelse:\\n',\n",
       "   '    print(\"Technical terms file not found. Please run the setup first.\")']},)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Load and display technical terms\\n\",\n",
    "    \"terms_file = project_root / \\\"data\\\" / \\\"tech_terms.json\\\"\\n\",\n",
    "    \"if terms_file.exists():\\n\",\n",
    "    \"    with open(terms_file, 'r') as f:\\n\",\n",
    "    \"        tech_terms = json.load(f)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(\\\"Technical Terms by Category:\\\")\\n\",\n",
    "    \"    for category, terms in tech_terms['technical_terms'].items():\\n\",\n",
    "    \"        if isinstance(terms, list):\\n\",\n",
    "    \"            print(f\\\"\\\\n{category.upper()}:\\\")\\n\",\n",
    "    \"            for term_data in terms:\\n\",\n",
    "    \"                term = term_data['term']\\n\",\n",
    "    \"                variations = term_data.get('variations', [])\\n\",\n",
    "    \"                print(f\\\"  - {term} ({', '.join(variations) if variations else 'no variations'})\\\")\\nelse:\\n\",\n",
    "    \"    print(\\\"Technical terms file not found. Please run the setup first.\\\")\"\n",
    "   ]\n",
    "  },"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095f3cb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c099a27",
   "metadata": {},
   "source": [
    "{\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. Generate Training Data\\n\",\n",
    "    \"\\n\",\n",
    "    \"Generate synthetic audio data using Text-to-Speech for training the model.\"\n",
    "   ]\n",
    "  },"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf957fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cell_type': 'code',\n",
       " 'execution_count': None,\n",
       " 'metadata': {},\n",
       " 'outputs': [],\n",
       " 'source': ['from data.audio_generator import TechTermAudioGenerator\\n',\n",
       "  '\\n',\n",
       "  '# Configure audio generation\\n',\n",
       "  'audio_config = {\\n',\n",
       "  \"    'voices': ['en-US-AriaNeural', 'en-US-JennyNeural'],  # Reduced for demo\\n\",\n",
       "  \"    'samples_per_term': 5,  # Reduced for demo\\n\",\n",
       "  \"    'sample_rate': 16000,\\n\",\n",
       "  \"    'apply_noise': True,\\n\",\n",
       "  \"    'speed_perturbation': True,\\n\",\n",
       "  \"    'templates': [\\n\",\n",
       "  '        \"I\\'m using {term} for this project\",\\n',\n",
       "  '        \"Can you help me with {term}?\",\\n',\n",
       "  '        \"The {term} documentation is great\",\\n',\n",
       "  '        \"Let\\'s configure {term} properly\"\\n',\n",
       "  '    ]\\n',\n",
       "  '}\\n',\n",
       "  '\\n',\n",
       "  'print(\"Audio generation configuration:\")\\n',\n",
       "  'for key, value in audio_config.items():\\n',\n",
       "  '    print(f\"  {key}: {value}\")']}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"from data.audio_generator import TechTermAudioGenerator\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Configure audio generation\\n\",\n",
    "    \"audio_config = {\\n\",\n",
    "    \"    'voices': ['en-US-AriaNeural', 'en-US-JennyNeural'],  # Reduced for demo\\n\",\n",
    "    \"    'samples_per_term': 5,  # Reduced for demo\\n\",\n",
    "    \"    'sample_rate': 16000,\\n\",\n",
    "    \"    'apply_noise': True,\\n\",\n",
    "    \"    'speed_perturbation': True,\\n\",\n",
    "    \"    'templates': [\\n\",\n",
    "    \"        \\\"I'm using {term} for this project\\\",\\n\",\n",
    "    \"        \\\"Can you help me with {term}?\\\",\\n\",\n",
    "    \"        \\\"The {term} documentation is great\\\",\\n\",\n",
    "    \"        \\\"Let's configure {term} properly\\\"\\n\",\n",
    "    \"    ]\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Audio generation configuration:\\\")\\n\",\n",
    "    \"for key, value in audio_config.items():\\n\",\n",
    "    \"    print(f\\\"  {key}: {value}\\\")\"\n",
    "   ]\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a2a4ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'cell_type': 'code',\n",
       "  'execution_count': None,\n",
       "  'metadata': {},\n",
       "  'outputs': [],\n",
       "  'source': ['# Generate training data (this will take a few minutes)\\n',\n",
       "   'async def generate_demo_data():\\n',\n",
       "   '    generator = TechTermAudioGenerator(audio_config)\\n',\n",
       "   '    generator.load_technical_terms(str(terms_file))\\n',\n",
       "   '    \\n',\n",
       "   '    print(\"Generating training data...\")\\n',\n",
       "   '    dataset = await generator.generate_audio_samples(str(project_root / \"data\"), train_split=0.8)\\n',\n",
       "   '    generator.save_dataset_metadata(dataset, str(project_root / \"data\"))\\n',\n",
       "   '    \\n',\n",
       "   '    print(f\"Generated {len(dataset[\\'train\\'])} training samples\")\\n',\n",
       "   '    print(f\"Generated {len(dataset[\\'validation\\'])} validation samples\")\\n',\n",
       "   '    return dataset\\n',\n",
       "   '\\n',\n",
       "   \"# Run if data doesn't exist\\n\",\n",
       "   'train_file = project_root / \"data\" / \"train_transcripts.json\"\\n',\n",
       "   'if not train_file.exists():\\n',\n",
       "   '    dataset = await generate_demo_data()\\n',\n",
       "   'else:\\n',\n",
       "   '    print(\"Training data already exists. Loading...\")\\n',\n",
       "   \"    with open(train_file, 'r') as f:\\n\",\n",
       "   '        train_data = json.load(f)\\n',\n",
       "   '    with open(project_root / \"data\" / \"val_transcripts.json\", \\'r\\') as f:\\n',\n",
       "   '        val_data = json.load(f)\\n',\n",
       "   \"    dataset = {'train': train_data, 'validation': val_data}\\n\",\n",
       "   '    print(f\"Loaded {len(dataset[\\'train\\'])} training samples\")\\n',\n",
       "   '    print(f\"Loaded {len(dataset[\\'validation\\'])} validation samples\")']},)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Generate training data (this will take a few minutes)\\n\",\n",
    "    \"async def generate_demo_data():\\n\",\n",
    "    \"    generator = TechTermAudioGenerator(audio_config)\\n\",\n",
    "    \"    generator.load_technical_terms(str(terms_file))\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(\\\"Generating training data...\\\")\\n\",\n",
    "    \"    dataset = await generator.generate_audio_samples(str(project_root / \\\"data\\\"), train_split=0.8)\\n\",\n",
    "    \"    generator.save_dataset_metadata(dataset, str(project_root / \\\"data\\\"))\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"Generated {len(dataset['train'])} training samples\\\")\\n\",\n",
    "    \"    print(f\\\"Generated {len(dataset['validation'])} validation samples\\\")\\n\",\n",
    "    \"    return dataset\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Run if data doesn't exist\\n\",\n",
    "    \"train_file = project_root / \\\"data\\\" / \\\"train_transcripts.json\\\"\\n\",\n",
    "    \"if not train_file.exists():\\n\",\n",
    "    \"    dataset = await generate_demo_data()\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"Training data already exists. Loading...\\\")\\n\",\n",
    "    \"    with open(train_file, 'r') as f:\\n\",\n",
    "    \"        train_data = json.load(f)\\n\",\n",
    "    \"    with open(project_root / \\\"data\\\" / \\\"val_transcripts.json\\\", 'r') as f:\\n\",\n",
    "    \"        val_data = json.load(f)\\n\",\n",
    "    \"    dataset = {'train': train_data, 'validation': val_data}\\n\",\n",
    "    \"    print(f\\\"Loaded {len(dataset['train'])} training samples\\\")\\n\",\n",
    "    \"    print(f\\\"Loaded {len(dataset['validation'])} validation samples\\\")\"\n",
    "   ]\n",
    "  },"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea2a14f",
   "metadata": {},
   "source": [
    "{\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. Examine Generated Data\\n\",\n",
    "    \"\\n\",\n",
    "    \"Let's look at some examples of the generated training data.\"\n",
    "   ]\n",
    "  },"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb1e5738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'cell_type': 'code',\n",
       "  'execution_count': None,\n",
       "  'metadata': {},\n",
       "  'outputs': [],\n",
       "  'source': ['import pandas as pd\\n',\n",
       "   'import random\\n',\n",
       "   '\\n',\n",
       "   '# Display sample training data\\n',\n",
       "   \"sample_data = random.sample(dataset['train'], min(10, len(dataset['train'])))\\n\",\n",
       "   'df = pd.DataFrame(sample_data)\\n',\n",
       "   '\\n',\n",
       "   'print(\"Sample Training Data:\")\\n',\n",
       "   'for i, row in df.iterrows():\\n',\n",
       "   '    print(f\"\\\\n{i+1}. Term: {row[\\'term\\']}\")\\n',\n",
       "   '    print(f\"   Text: {row[\\'transcription\\']}\")\\n',\n",
       "   '    print(f\"   Voice: {row[\\'voice\\']}\")\\n',\n",
       "   '    print(f\"   Audio: {Path(row[\\'audio_path\\']).name}\")']},)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import random\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Display sample training data\\n\",\n",
    "    \"sample_data = random.sample(dataset['train'], min(10, len(dataset['train'])))\\n\",\n",
    "    \"df = pd.DataFrame(sample_data)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Sample Training Data:\\\")\\n\",\n",
    "    \"for i, row in df.iterrows():\\n\",\n",
    "    \"    print(f\\\"\\\\n{i+1}. Term: {row['term']}\\\")\\n\",\n",
    "    \"    print(f\\\"   Text: {row['transcription']}\\\")\\n\",\n",
    "    \"    print(f\\\"   Voice: {row['voice']}\\\")\\n\",\n",
    "    \"    print(f\\\"   Audio: {Path(row['audio_path']).name}\\\")\"\n",
    "   ]\n",
    "  },"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b7406ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'cell_type': 'code',\n",
       "  'execution_count': None,\n",
       "  'metadata': {},\n",
       "  'outputs': [],\n",
       "  'source': ['# Analyze data distribution\\n',\n",
       "   'import matplotlib.pyplot as plt\\n',\n",
       "   'import seaborn as sns\\n',\n",
       "   '\\n',\n",
       "   '# Count samples per term\\n',\n",
       "   \"train_df = pd.DataFrame(dataset['train'])\\n\",\n",
       "   \"term_counts = train_df['term'].value_counts()\\n\",\n",
       "   '\\n',\n",
       "   'plt.figure(figsize=(12, 6))\\n',\n",
       "   'plt.subplot(1, 2, 1)\\n',\n",
       "   \"term_counts.plot(kind='bar')\\n\",\n",
       "   \"plt.title('Samples per Technical Term')\\n\",\n",
       "   \"plt.xlabel('Terms')\\n\",\n",
       "   \"plt.ylabel('Number of Samples')\\n\",\n",
       "   'plt.xticks(rotation=45)\\n',\n",
       "   '\\n',\n",
       "   '# Count samples per voice\\n',\n",
       "   'plt.subplot(1, 2, 2)\\n',\n",
       "   \"voice_counts = train_df['voice'].value_counts()\\n\",\n",
       "   \"voice_counts.plot(kind='pie', autopct='%1.1f%%')\\n\",\n",
       "   \"plt.title('Distribution by Voice')\\n\",\n",
       "   '\\n',\n",
       "   'plt.tight_layout()\\n',\n",
       "   'plt.show()\\n',\n",
       "   '\\n',\n",
       "   'print(f\"\\\\nDataset Statistics:\")\\n',\n",
       "   'print(f\"Total training samples: {len(dataset[\\'train\\'])}\")\\n',\n",
       "   'print(f\"Total validation samples: {len(dataset[\\'validation\\'])}\")\\n',\n",
       "   'print(f\"Unique terms: {len(term_counts)}\")\\n',\n",
       "   'print(f\"Voices used: {len(voice_counts)}\")']},)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Analyze data distribution\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Count samples per term\\n\",\n",
    "    \"train_df = pd.DataFrame(dataset['train'])\\n\",\n",
    "    \"term_counts = train_df['term'].value_counts()\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.figure(figsize=(12, 6))\\n\",\n",
    "    \"plt.subplot(1, 2, 1)\\n\",\n",
    "    \"term_counts.plot(kind='bar')\\n\",\n",
    "    \"plt.title('Samples per Technical Term')\\n\",\n",
    "    \"plt.xlabel('Terms')\\n\",\n",
    "    \"plt.ylabel('Number of Samples')\\n\",\n",
    "    \"plt.xticks(rotation=45)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Count samples per voice\\n\",\n",
    "    \"plt.subplot(1, 2, 2)\\n\",\n",
    "    \"voice_counts = train_df['voice'].value_counts()\\n\",\n",
    "    \"voice_counts.plot(kind='pie', autopct='%1.1f%%')\\n\",\n",
    "    \"plt.title('Distribution by Voice')\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nDataset Statistics:\\\")\\n\",\n",
    "    \"print(f\\\"Total training samples: {len(dataset['train'])}\\\")\\n\",\n",
    "    \"print(f\\\"Total validation samples: {len(dataset['validation'])}\\\")\\n\",\n",
    "    \"print(f\\\"Unique terms: {len(term_counts)}\\\")\\n\",\n",
    "    \"print(f\\\"Voices used: {len(voice_counts)}\\\")\"\n",
    "   ]\n",
    "  },"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0991ff8e",
   "metadata": {},
   "source": [
    "{\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4. Initialize and Train Model\\n\",\n",
    "    \"\\n\",\n",
    "    \"Now let's set up the Whisper model for fine-tuning with LoRA.\"\n",
    "   ]\n",
    "  },"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ad6ab79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'cell_type': 'code',\n",
       "  'execution_count': None,\n",
       "  'metadata': {},\n",
       "  'outputs': [],\n",
       "  'source': ['from src.model.whisper_trainer import WhisperTechTrainer\\n',\n",
       "   '\\n',\n",
       "   '# Adjust config for demo (smaller values for faster training)\\n',\n",
       "   'demo_config = config.copy()\\n',\n",
       "   \"demo_config['training'].update({\\n\",\n",
       "   \"    'num_epochs': 3,  # Reduced for demo\\n\",\n",
       "   \"    'batch_size': 2,  # Reduced for demo\\n\",\n",
       "   \"    'save_steps': 50,\\n\",\n",
       "   \"    'eval_steps': 50,\\n\",\n",
       "   \"    'logging_steps': 25,\\n\",\n",
       "   '    \\'output_dir\\': str(project_root / \"models\" / \"whisper-demo-finetuned\")\\n',\n",
       "   '})\\n',\n",
       "   '\\n',\n",
       "   'print(\"Demo training configuration:\")\\n',\n",
       "   \"for key, value in demo_config['training'].items():\\n\",\n",
       "   '    print(f\"  {key}: {value}\")']},)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"from src.model.whisper_trainer import WhisperTechTrainer\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Adjust config for demo (smaller values for faster training)\\n\",\n",
    "    \"demo_config = config.copy()\\n\",\n",
    "    \"demo_config['training'].update({\\n\",\n",
    "    \"    'num_epochs': 3,  # Reduced for demo\\n\",\n",
    "    \"    'batch_size': 2,  # Reduced for demo\\n\",\n",
    "    \"    'save_steps': 50,\\n\",\n",
    "    \"    'eval_steps': 50,\\n\",\n",
    "    \"    'logging_steps': 25,\\n\",\n",
    "    \"    'output_dir': str(project_root / \\\"models\\\" / \\\"whisper-demo-finetuned\\\")\\n\",\n",
    "    \"})\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Demo training configuration:\\\")\\n\",\n",
    "    \"for key, value in demo_config['training'].items():\\n\",\n",
    "    \"    print(f\\\"  {key}: {value}\\\")\"\n",
    "   ]\n",
    "  },"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d14fcf32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'cell_type': 'code',\n",
       "  'execution_count': None,\n",
       "  'metadata': {},\n",
       "  'outputs': [],\n",
       "  'source': ['# Initialize trainer\\n',\n",
       "   'print(\"Initializing Whisper trainer...\")\\n',\n",
       "   'trainer = WhisperTechTrainer(demo_config)\\n',\n",
       "   'trainer.setup_model()\\n',\n",
       "   'print(\"âœ“ Model initialized with LoRA configuration\")']},)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Initialize trainer\\n\",\n",
    "    \"print(\\\"Initializing Whisper trainer...\\\")\\n\",\n",
    "    \"trainer = WhisperTechTrainer(demo_config)\\n\",\n",
    "    \"trainer.setup_model()\\n\",\n",
    "    \"print(\\\"âœ“ Model initialized with LoRA configuration\\\")\"\n",
    "   ]\n",
    "  },"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "edd2b9da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'cell_type': 'code',\n",
       "  'execution_count': None,\n",
       "  'metadata': {},\n",
       "  'outputs': [],\n",
       "  'source': ['# Prepare datasets\\n',\n",
       "   'print(\"Preparing datasets...\")\\n',\n",
       "   'train_dataset = trainer.load_dataset(\\n',\n",
       "   '    str(project_root / \"data\" / \"train_audio\"),\\n',\n",
       "   '    str(project_root / \"data\" / \"train_transcripts.json\")\\n',\n",
       "   ')\\n',\n",
       "   'train_dataset = trainer.prepare_dataset(train_dataset)\\n',\n",
       "   '\\n',\n",
       "   'val_dataset = trainer.load_dataset(\\n',\n",
       "   '    str(project_root / \"data\" / \"val_audio\"),\\n',\n",
       "   '    str(project_root / \"data\" / \"val_transcripts.json\")\\n',\n",
       "   ')\\n',\n",
       "   'val_dataset = trainer.prepare_dataset(val_dataset)\\n',\n",
       "   '\\n',\n",
       "   'print(f\"âœ“ Training dataset: {len(train_dataset)} samples\")\\n',\n",
       "   'print(f\"âœ“ Validation dataset: {len(val_dataset)} samples\")']},)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Prepare datasets\\n\",\n",
    "    \"print(\\\"Preparing datasets...\\\")\\n\",\n",
    "    \"train_dataset = trainer.load_dataset(\\n\",\n",
    "    \"    str(project_root / \\\"data\\\" / \\\"train_audio\\\"),\\n\",\n",
    "    \"    str(project_root / \\\"data\\\" / \\\"train_transcripts.json\\\")\\n\",\n",
    "    \")\\n\",\n",
    "    \"train_dataset = trainer.prepare_dataset(train_dataset)\\n\",\n",
    "    \"\\n\",\n",
    "    \"val_dataset = trainer.load_dataset(\\n\",\n",
    "    \"    str(project_root / \\\"data\\\" / \\\"val_audio\\\"),\\n\",\n",
    "    \"    str(project_root / \\\"data\\\" / \\\"val_transcripts.json\\\")\\n\",\n",
    "    \")\\n\",\n",
    "    \"val_dataset = trainer.prepare_dataset(val_dataset)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"âœ“ Training dataset: {len(train_dataset)} samples\\\")\\n\",\n",
    "    \"print(f\\\"âœ“ Validation dataset: {len(val_dataset)} samples\\\")\"\n",
    "   ]\n",
    "  },"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "048fac1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'cell_type': 'code',\n",
       "  'execution_count': None,\n",
       "  'metadata': {},\n",
       "  'outputs': [],\n",
       "  'source': ['# Start training (this will take some time)\\n',\n",
       "   'print(\"Starting training...\")\\n',\n",
       "   'print(\"Note: This may take 15-30 minutes depending on your hardware\")\\n',\n",
       "   '\\n',\n",
       "   'try:\\n',\n",
       "   '    trainer.train(train_dataset, val_dataset)\\n',\n",
       "   '    print(\"\\\\nâœ“ Training completed successfully!\")\\nexcept Exception as e:\\n',\n",
       "   '    print(f\"Training failed: {str(e)}\")\\n',\n",
       "   '    print(\"This might be due to insufficient GPU memory or other hardware limitations.\")']},)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Start training (this will take some time)\\n\",\n",
    "    \"print(\\\"Starting training...\\\")\\n\",\n",
    "    \"print(\\\"Note: This may take 15-30 minutes depending on your hardware\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"try:\\n\",\n",
    "    \"    trainer.train(train_dataset, val_dataset)\\n\",\n",
    "    \"    print(\\\"\\\\nâœ“ Training completed successfully!\\\")\\nexcept Exception as e:\\n\",\n",
    "    \"    print(f\\\"Training failed: {str(e)}\\\")\\n\",\n",
    "    \"    print(\\\"This might be due to insufficient GPU memory or other hardware limitations.\\\")\"\n",
    "   ]\n",
    "  },"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fb9928",
   "metadata": {},
   "source": [
    "{\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 5. Evaluate the Model\\n\",\n",
    "    \"\\n\",\n",
    "    \"Test the fine-tuned model and compare it with the original Whisper model.\"\n",
    "   ]\n",
    "  },"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "59c9fea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'cell_type': 'code',\n",
       "  'execution_count': None,\n",
       "  'metadata': {},\n",
       "  'outputs': [],\n",
       "  'source': ['# Test inference on a sample\\n',\n",
       "   'if val_dataset and len(val_dataset) > 0:\\n',\n",
       "   '    # Get a random validation sample\\n',\n",
       "   '    import random\\n',\n",
       "   '    sample_idx = random.randint(0, len(val_dataset) - 1)\\n',\n",
       "   '    sample = val_dataset[sample_idx]\\n',\n",
       "   '    \\n',\n",
       "   '    # Get the audio path from the original validation data\\n',\n",
       "   \"    val_data = dataset['validation']\\n\",\n",
       "   \"    audio_path = val_data[sample_idx]['audio_path']\\n\",\n",
       "   \"    reference_text = val_data[sample_idx]['transcription']\\n\",\n",
       "   '    \\n',\n",
       "   '    print(f\"Testing on sample: {Path(audio_path).name}\")\\n',\n",
       "   '    print(f\"Reference text: {reference_text}\")\\n',\n",
       "   '    \\n',\n",
       "   '    # Transcribe with fine-tuned model\\n',\n",
       "   '    prediction = trainer.inference(audio_path)\\n',\n",
       "   '    print(f\"Fine-tuned prediction: {prediction}\")\\n',\n",
       "   '    \\n',\n",
       "   '    # Calculate simple accuracy\\n',\n",
       "   '    import jiwer\\n',\n",
       "   '    wer = jiwer.wer([reference_text], [prediction])\\n',\n",
       "   '    print(f\"Word Error Rate: {wer:.2%}\")\\nelse:\\n',\n",
       "   '    print(\"No validation data available for testing\")']},)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Test inference on a sample\\n\",\n",
    "    \"if val_dataset and len(val_dataset) > 0:\\n\",\n",
    "    \"    # Get a random validation sample\\n\",\n",
    "    \"    import random\\n\",\n",
    "    \"    sample_idx = random.randint(0, len(val_dataset) - 1)\\n\",\n",
    "    \"    sample = val_dataset[sample_idx]\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Get the audio path from the original validation data\\n\",\n",
    "    \"    val_data = dataset['validation']\\n\",\n",
    "    \"    audio_path = val_data[sample_idx]['audio_path']\\n\",\n",
    "    \"    reference_text = val_data[sample_idx]['transcription']\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"Testing on sample: {Path(audio_path).name}\\\")\\n\",\n",
    "    \"    print(f\\\"Reference text: {reference_text}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Transcribe with fine-tuned model\\n\",\n",
    "    \"    prediction = trainer.inference(audio_path)\\n\",\n",
    "    \"    print(f\\\"Fine-tuned prediction: {prediction}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Calculate simple accuracy\\n\",\n",
    "    \"    import jiwer\\n\",\n",
    "    \"    wer = jiwer.wer([reference_text], [prediction])\\n\",\n",
    "    \"    print(f\\\"Word Error Rate: {wer:.2%}\\\")\\nelse:\\n\",\n",
    "    \"    print(\\\"No validation data available for testing\\\")\"\n",
    "   ]\n",
    "  },"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f899b6",
   "metadata": {},
   "source": [
    "{\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 6. Test on Custom Audio (Optional)\\n\",\n",
    "    \"\\n\",\n",
    "    \"If you have your own audio files, you can test them here.\"\n",
    "   ]\n",
    "  },"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6616bfeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'cell_type': 'code',\n",
       "  'execution_count': None,\n",
       "  'metadata': {},\n",
       "  'outputs': [],\n",
       "  'source': ['# Test on custom audio file\\n',\n",
       "   '# Replace with your own audio file path\\n',\n",
       "   'custom_audio_path = \"/path/to/your/audio/file.wav\"\\n',\n",
       "   '\\n',\n",
       "   'if Path(custom_audio_path).exists():\\n',\n",
       "   '    print(f\"Testing on custom audio: {Path(custom_audio_path).name}\")\\n',\n",
       "   '    \\n',\n",
       "   '    # Transcribe\\n',\n",
       "   '    result = trainer.inference(custom_audio_path)\\n',\n",
       "   '    print(f\"Transcription: {result}\")\\n',\n",
       "   '    \\n',\n",
       "   '    # Check for technical terms\\n',\n",
       "   '    found_terms = []\\n',\n",
       "   '    result_lower = result.lower()\\n',\n",
       "   '    \\n',\n",
       "   \"    for category in tech_terms['technical_terms'].values():\\n\",\n",
       "   '        if isinstance(category, list):\\n',\n",
       "   '            for term_data in category:\\n',\n",
       "   \"                term = term_data['term'].lower()\\n\",\n",
       "   \"                variations = [v.lower() for v in term_data.get('variations', [])]\\n\",\n",
       "   '                \\n',\n",
       "   '                if term in result_lower or any(var in result_lower for var in variations):\\n',\n",
       "   \"                    found_terms.append(term_data['term'])\\n\",\n",
       "   '    \\n',\n",
       "   '    if found_terms:\\n',\n",
       "   '        print(f\"Technical terms detected: {\\', \\'.join(found_terms)}\")\\n',\n",
       "   '    else:\\n',\n",
       "   '        print(\"No technical terms detected in transcription\")\\nelse:\\n',\n",
       "   '    print(\"Custom audio file not found. Skipping custom test.\")\\n',\n",
       "   '    print(\"To test your own audio, replace \\'custom_audio_path\\' with your file path.\")']},)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Test on custom audio file\\n\",\n",
    "    \"# Replace with your own audio file path\\n\",\n",
    "    \"custom_audio_path = \\\"/path/to/your/audio/file.wav\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"if Path(custom_audio_path).exists():\\n\",\n",
    "    \"    print(f\\\"Testing on custom audio: {Path(custom_audio_path).name}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Transcribe\\n\",\n",
    "    \"    result = trainer.inference(custom_audio_path)\\n\",\n",
    "    \"    print(f\\\"Transcription: {result}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Check for technical terms\\n\",\n",
    "    \"    found_terms = []\\n\",\n",
    "    \"    result_lower = result.lower()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    for category in tech_terms['technical_terms'].values():\\n\",\n",
    "    \"        if isinstance(category, list):\\n\",\n",
    "    \"            for term_data in category:\\n\",\n",
    "    \"                term = term_data['term'].lower()\\n\",\n",
    "    \"                variations = [v.lower() for v in term_data.get('variations', [])]\\n\",\n",
    "    \"                \\n\",\n",
    "    \"                if term in result_lower or any(var in result_lower for var in variations):\\n\",\n",
    "    \"                    found_terms.append(term_data['term'])\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    if found_terms:\\n\",\n",
    "    \"        print(f\\\"Technical terms detected: {', '.join(found_terms)}\\\")\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        print(\\\"No technical terms detected in transcription\\\")\\nelse:\\n\",\n",
    "    \"    print(\\\"Custom audio file not found. Skipping custom test.\\\")\\n\",\n",
    "    \"    print(\\\"To test your own audio, replace 'custom_audio_path' with your file path.\\\")\"\n",
    "   ]\n",
    "  },"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9145c7c7",
   "metadata": {},
   "source": [
    "{\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 7. Model Analysis\\n\",\n",
    "    \"\\n\",\n",
    "    \"Analyze the trained model's performance and characteristics.\"\n",
    "   ]\n",
    "  },"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3ff228df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'cell_type': 'code',\n",
       "  'execution_count': None,\n",
       "  'metadata': {},\n",
       "  'outputs': [],\n",
       "  'source': ['# Model information\\n',\n",
       "   'print(\"Model Information:\")\\n',\n",
       "   'print(f\"Base model: {demo_config[\\'model\\'][\\'name\\']}\")\\n',\n",
       "   'print(f\"Language: {demo_config[\\'model\\'][\\'language\\']}\")\\n',\n",
       "   'print(f\"Task: {demo_config[\\'model\\'][\\'task\\']}\")\\n',\n",
       "   'print(f\"Training epochs: {demo_config[\\'training\\'][\\'num_epochs\\']}\")\\n',\n",
       "   'print(f\"LoRA enabled: {demo_config[\\'training\\'][\\'use_lora\\']}\")\\n',\n",
       "   '\\n',\n",
       "   \"if demo_config['training']['use_lora']:\\n\",\n",
       "   '    print(f\"LoRA rank: {demo_config[\\'training\\'][\\'lora_rank\\']}\")\\n',\n",
       "   '    print(f\"LoRA alpha: {demo_config[\\'training\\'][\\'lora_alpha\\']}\")\\n',\n",
       "   '\\n',\n",
       "   '# Model size information\\n',\n",
       "   \"model_path = Path(demo_config['training']['output_dir'])\\n\",\n",
       "   'if model_path.exists():\\n',\n",
       "   \"    model_size = sum(f.stat().st_size for f in model_path.rglob('*') if f.is_file())\\n\",\n",
       "   '    print(f\"\\\\nModel directory size: {model_size / (1024**2):.1f} MB\")\\n',\n",
       "   '    print(f\"Model saved to: {model_path}\")\\nelse:\\n',\n",
       "   '    print(\"\\\\nModel directory not found - training may not have completed successfully\")']},)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Model information\\n\",\n",
    "    \"print(\\\"Model Information:\\\")\\n\",\n",
    "    \"print(f\\\"Base model: {demo_config['model']['name']}\\\")\\n\",\n",
    "    \"print(f\\\"Language: {demo_config['model']['language']}\\\")\\n\",\n",
    "    \"print(f\\\"Task: {demo_config['model']['task']}\\\")\\n\",\n",
    "    \"print(f\\\"Training epochs: {demo_config['training']['num_epochs']}\\\")\\n\",\n",
    "    \"print(f\\\"LoRA enabled: {demo_config['training']['use_lora']}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"if demo_config['training']['use_lora']:\\n\",\n",
    "    \"    print(f\\\"LoRA rank: {demo_config['training']['lora_rank']}\\\")\\n\",\n",
    "    \"    print(f\\\"LoRA alpha: {demo_config['training']['lora_alpha']}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Model size information\\n\",\n",
    "    \"model_path = Path(demo_config['training']['output_dir'])\\n\",\n",
    "    \"if model_path.exists():\\n\",\n",
    "    \"    model_size = sum(f.stat().st_size for f in model_path.rglob('*') if f.is_file())\\n\",\n",
    "    \"    print(f\\\"\\\\nModel directory size: {model_size / (1024**2):.1f} MB\\\")\\n\",\n",
    "    \"    print(f\\\"Model saved to: {model_path}\\\")\\nelse:\\n\",\n",
    "    \"    print(\\\"\\\\nModel directory not found - training may not have completed successfully\\\")\"\n",
    "   ]\n",
    "  },"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f955041",
   "metadata": {},
   "source": [
    "{\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 8. Next Steps\\n\",\n",
    "    \"\\n\",\n",
    "    \"This demo showed you how to:\\n\",\n",
    "    \"1. Generate training data with technical terms\\n\",\n",
    "    \"2. Fine-tune Whisper using LoRA\\n\",\n",
    "    \"3. Test the fine-tuned model\\n\",\n",
    "    \"\\n\",\n",
    "    \"For production use:\\n\",\n",
    "    \"- Increase `samples_per_term` and `num_epochs` for better results\\n\",\n",
    "    \"- Add more diverse sentence templates\\n\",\n",
    "    \"- Include real recorded audio in your training data\\n\",\n",
    "    \"- Run full evaluation with the evaluation script\\n\",\n",
    "    \"- Compare with the original model using the comparison tools\"\n",
    "   ]\n",
    "  },"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e81fd0e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cell_type': 'code',\n",
       " 'execution_count': None,\n",
       " 'metadata': {},\n",
       " 'outputs': [],\n",
       " 'source': ['print(\"Demo completed! ðŸŽ‰\")\\n',\n",
       "  'print(\"\\\\nTo run full training and evaluation:\")\\n',\n",
       "  'print(\"1. python scripts/generate_training_data.py\")\\n',\n",
       "  'print(\"2. python scripts/train_model.py --model_size large-v3 --epochs 10\")\\n',\n",
       "  'print(\"3. python scripts/evaluate_model.py --compare_original\")\\n',\n",
       "  'print(\"4. python scripts/inference.py --audio_path your_audio.wav\")']}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"Demo completed! ðŸŽ‰\\\")\\n\",\n",
    "    \"print(\\\"\\\\nTo run full training and evaluation:\\\")\\n\",\n",
    "    \"print(\\\"1. python scripts/generate_training_data.py\\\")\\n\",\n",
    "    \"print(\\\"2. python scripts/train_model.py --model_size large-v3 --epochs 10\\\")\\n\",\n",
    "    \"print(\\\"3. python scripts/evaluate_model.py --compare_original\\\")\\n\",\n",
    "    \"print(\\\"4. python scripts/inference.py --audio_path your_audio.wav\\\")\"\n",
    "   ]\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6de308cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metadata': {'kernelspec': {'display_name': 'Python 3',\n",
       "   'language': 'python',\n",
       "   'name': 'python3'},\n",
       "  'language_info': {'codemirror_mode': {'name': 'ipython', 'version': 3},\n",
       "   'file_extension': '.py',\n",
       "   'mimetype': 'text/x-python',\n",
       "   'name': 'python',\n",
       "   'nbconvert_exporter': 'python',\n",
       "   'pygments_lexer': 'ipython3',\n",
       "   'version': '3.8.0'}},\n",
       " 'nbformat': 4,\n",
       " 'nbformat_minor': 4}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "  \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.8.0\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    " }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
