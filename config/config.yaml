# Whisper Fine-tuning Configuration

# Model configuration
model:
  name: "openai/whisper-large-v3" # or "openai/whisper-large-v3-turbo"
  language: "en"
  task: "transcribe"

# Training configuration
training:
  output_dir: "./models/whisper-tech-finetuned"
  num_epochs: 10
  batch_size: 8
  gradient_accumulation_steps: 4
  learning_rate: 1e-5
  warmup_steps: 500
  weight_decay: 0.01
  max_grad_norm: 1.0

  # LoRA configuration for efficient fine-tuning
  use_lora: true
  lora_rank: 64
  lora_alpha: 128
  lora_dropout: 0.1

  # Mixed precision training
  fp16: true
  dataloader_num_workers: 4

  # Checkpointing
  save_steps: 500
  eval_steps: 500
  logging_steps: 100
  save_total_limit: 3

# Data configuration
data:
  # Training data paths
  train_audio_dir: "./data/train_audio"
  train_transcripts: "./data/train_transcripts.json"

  # Validation data
  val_audio_dir: "./data/val_audio"
  val_transcripts: "./data/val_transcripts.json"

  # Audio preprocessing
  sampling_rate: 16000
  max_audio_length: 30 # seconds
  min_audio_length: 1 # seconds

  # Data augmentation
  apply_noise: true
  noise_probability: 0.3
  speed_perturbation: true
  speed_range: [0.9, 1.1]

# Technical terms to focus on
technical_terms:
  programming:
    - "maven"
    - "github"
    - "git"
    - "docker"
    - "kubernetes"
    - "jenkins"
    - "gradle"
    - "npm"
    - "pip"
    - "conda"

  ai_ml:
    - "openai"
    - "chatgpt"
    - "gpt"
    - "llm"
    - "large language model"
    - "transformer"
    - "bert"
    - "pytorch"
    - "tensorflow"
    - "hugging face"
    - "groq"
    - "grok"
    - "anthropic"
    - "claude"

  cloud_services:
    - "aws"
    - "azure"
    - "gcp"
    - "google cloud"
    - "portkey"
    - "vercel"
    - "netlify"
    - "heroku"

# Audio generation for training data
audio_generation:
  # Text-to-speech settings
  tts_service: "edge-tts" # or "gtts"
  voices:
    - "en-US-AriaNeural"
    - "en-US-JennyNeural"
    - "en-US-GuyNeural"
    - "en-GB-SoniaNeural"
    - "en-AU-NatashaNeural"

  # Sentence templates for context
  templates:
    - "I'm using {term} for this project"
    - "Let's install {term} first"
    - "The {term} documentation is helpful"
    - "Can you help me with {term}?"
    - "I need to configure {term} properly"
    - "The {term} API is quite powerful"
    - "We should migrate to {term}"
    - "How do I use {term} effectively?"
    - "{term} is a great tool for developers"
    - "I'm having issues with {term}"

  # Audio quality settings
  sample_rate: 16000
  bit_depth: 16
  samples_per_term: 20
  background_noise: true

# Evaluation configuration
evaluation:
  metrics:
    - "wer" # Word Error Rate
    - "cer" # Character Error Rate
    - "term_accuracy" # Technical term specific accuracy

  # Test sets
  test_sets:
    - name: "technical_terms"
      path: "./data/test_technical.json"
    - name: "general_speech"
      path: "./data/test_general.json"

# Logging and monitoring
logging:
  level: "INFO"
  use_wandb: true
  wandb_project: "whisper-tech-finetuning"
  use_tensorboard: true

# Hardware optimization
hardware:
  device: "auto" # auto, cpu, cuda
  mixed_precision: true
  compile_model: false # PyTorch 2.0 compilation
  gradient_checkpointing: true
